{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig, LlavaForConditionalGeneration, pipeline, AutoTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b575b23d574b1fb96c0ee20f01d257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hugging Face model id\n",
    "model_id = \"mistral-community/pixtral-12b\" \n",
    "\n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "# model = AutoModelForVision2Seq.from_pretrained(\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    # attn_implementation=\"flash_attention_2\", # not supported for training\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abe116eab384c139bf0d79a4303dd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00007-9de56bcdafdee2d8.parquet:   0%|          | 0.00/399M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c974937f509f4aad8702a7b9a59903f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00007-d4acaf169b202bde.parquet:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f168b6202e44d2ad696c1805d94167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00007-3eeb547f5ee2bc77.parquet:   0%|          | 0.00/337M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ee89d9f1ad407e8d8dca2715d82413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00003-of-00007-db06d49ad5d281c2.parquet:   0%|          | 0.00/358M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee5867feda14f0abfb4521c7185b03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00004-of-00007-34cdb0916951598d.parquet:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32adefae8ed24130abe6aa9888711306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00005-of-00007-25f227541c143e60.parquet:   0%|          | 0.00/317M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5b28e63c834e96be603dedc8e5ab32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00006-of-00007-84404baa7f02576e.parquet:   0%|          | 0.00/339M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d42329c0a54d019edd0fc8868050de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00002-032e07b311d1db77.parquet:   0%|          | 0.00/296M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd6c4a94d5a4766b26741fef0c63f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00002-d55c6542fe70f451.parquet:   0%|          | 0.00/294M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a2f4b823ab45d0b6be8ed693b6eb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/19877 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e050111fc3d43a79a1d50c19cd32a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"advancedcv/Food500Cap\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset, model, processor, max = None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_categories = dataset.unique(\"cat\")\n",
    "    \n",
    "    # If max is not None, limit the number of samples to max\n",
    "    if max is not None:\n",
    "        dataset = dataset.select(range(min(max, len(dataset))))\n",
    "        \n",
    "    for item in tqdm(dataset):\n",
    "        image = item['image']\n",
    "        category = str(item['cat'])\n",
    "        # caption = item['caption']\n",
    "\n",
    "        gt_cat_index = all_categories.index(category)\n",
    "        wrong_cat_indexes = [i for i in torch.randperm(len(all_categories)) if i != gt_cat_index][:3]\n",
    "\n",
    "        categories_options_index = [gt_cat_index] + wrong_cat_indexes\n",
    "        random.shuffle(categories_options_index)\n",
    "\n",
    "        categories_options = [all_categories[i] for i in categories_options_index]\n",
    "\n",
    "        PROMPT = f\"<s>[INST]Which one of the following categories does this image belong to?:\\n {\n",
    "            \", \".join(categories_options)\n",
    "        }\\n[IMG][/INST]\"\n",
    "\n",
    "        IMG_URLS = [\n",
    "            image\n",
    "        ]\n",
    "\n",
    "        inputs = processor(text=PROMPT, images=IMG_URLS, return_tensors=\"pt\").to(\"cuda\")\n",
    "        generate_ids = model.generate(**inputs, max_new_tokens=100)\n",
    "        output = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "        if category.lower() in output.lower():\n",
    "            correct += 1\n",
    "        \n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  1%|          | 1/100 [00:06<10:33,  6.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  2%|▏         | 2/100 [00:12<10:30,  6.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  3%|▎         | 3/100 [00:19<10:31,  6.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  4%|▍         | 4/100 [00:26<10:32,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  5%|▌         | 5/100 [00:31<09:40,  6.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  6%|▌         | 6/100 [00:37<09:48,  6.26s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  7%|▋         | 7/100 [00:41<08:29,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  8%|▊         | 8/100 [00:48<09:07,  5.95s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  9%|▉         | 9/100 [00:53<08:12,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 10%|█         | 10/100 [00:55<06:52,  4.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 11%|█         | 11/100 [01:01<07:19,  4.94s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 12%|█▏        | 12/100 [01:07<07:35,  5.17s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 13%|█▎        | 13/100 [01:14<08:16,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 14%|█▍        | 14/100 [01:21<08:55,  6.22s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 15%|█▌        | 15/100 [01:28<08:54,  6.29s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 16%|█▌        | 16/100 [01:31<07:45,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 17%|█▋        | 17/100 [01:36<07:25,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 18%|█▊        | 18/100 [01:43<07:50,  5.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 19%|█▉        | 19/100 [01:50<08:26,  6.25s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 20%|██        | 20/100 [01:55<07:39,  5.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 21%|██        | 21/100 [02:01<07:40,  5.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 22%|██▏       | 22/100 [02:02<05:42,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 23%|██▎       | 23/100 [02:09<06:30,  5.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 24%|██▍       | 24/100 [02:15<06:49,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 25%|██▌       | 25/100 [02:22<07:32,  6.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 26%|██▌       | 26/100 [02:25<06:07,  4.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 27%|██▋       | 27/100 [02:30<06:05,  5.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 28%|██▊       | 28/100 [02:36<06:24,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 29%|██▉       | 29/100 [02:42<06:34,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 30%|███       | 30/100 [02:47<06:20,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 31%|███       | 31/100 [02:55<06:56,  6.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 32%|███▏      | 32/100 [02:59<06:12,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 33%|███▎      | 33/100 [03:05<06:20,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 34%|███▍      | 34/100 [03:11<06:30,  5.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 35%|███▌      | 35/100 [03:18<06:36,  6.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 36%|███▌      | 36/100 [03:24<06:38,  6.23s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 37%|███▋      | 37/100 [03:32<06:58,  6.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 38%|███▊      | 38/100 [03:35<05:46,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 39%|███▉      | 39/100 [03:40<05:35,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 40%|████      | 40/100 [03:45<05:16,  5.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 41%|████      | 41/100 [03:49<04:52,  4.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 42%|████▏     | 42/100 [03:56<05:09,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 43%|████▎     | 43/100 [04:02<05:19,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 44%|████▍     | 44/100 [04:06<04:44,  5.09s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 45%|████▌     | 45/100 [04:10<04:23,  4.80s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 46%|████▌     | 46/100 [04:14<04:14,  4.72s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 47%|████▋     | 47/100 [04:21<04:34,  5.17s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 48%|████▊     | 48/100 [04:27<04:45,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 49%|████▉     | 49/100 [04:31<04:14,  5.00s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 50%|█████     | 50/100 [04:37<04:28,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 51%|█████     | 51/100 [04:40<03:51,  4.71s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 52%|█████▏    | 52/100 [04:46<03:59,  4.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 53%|█████▎    | 53/100 [04:53<04:24,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 54%|█████▍    | 54/100 [04:56<03:41,  4.80s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 55%|█████▌    | 55/100 [05:00<03:26,  4.60s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 56%|█████▌    | 56/100 [05:03<02:58,  4.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 57%|█████▋    | 57/100 [05:07<03:02,  4.24s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 58%|█████▊    | 58/100 [05:14<03:27,  4.95s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 59%|█████▉    | 59/100 [05:20<03:32,  5.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 60%|██████    | 60/100 [05:22<02:55,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 61%|██████    | 61/100 [05:26<02:44,  4.21s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 62%|██████▏   | 62/100 [05:29<02:27,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 63%|██████▎   | 63/100 [05:36<02:57,  4.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 64%|██████▍   | 64/100 [05:42<03:09,  5.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 65%|██████▌   | 65/100 [05:45<02:40,  4.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 66%|██████▌   | 66/100 [05:51<02:41,  4.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 67%|██████▋   | 67/100 [05:54<02:25,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 68%|██████▊   | 68/100 [06:01<02:42,  5.07s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 69%|██████▉   | 69/100 [06:07<02:51,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 70%|███████   | 70/100 [06:15<03:00,  6.02s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 71%|███████   | 71/100 [06:22<03:06,  6.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 72%|███████▏  | 72/100 [06:27<02:48,  6.02s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 73%|███████▎  | 73/100 [06:34<02:51,  6.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 74%|███████▍  | 74/100 [06:40<02:39,  6.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 75%|███████▌  | 75/100 [06:43<02:10,  5.20s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 76%|███████▌  | 76/100 [06:50<02:20,  5.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 77%|███████▋  | 77/100 [06:53<01:56,  5.06s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 78%|███████▊  | 78/100 [06:58<01:45,  4.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 79%|███████▉  | 79/100 [07:00<01:25,  4.06s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 80%|████████  | 80/100 [07:07<01:41,  5.07s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 81%|████████  | 81/100 [07:15<01:50,  5.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 82%|████████▏ | 82/100 [07:22<01:52,  6.28s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 83%|████████▎ | 83/100 [07:27<01:39,  5.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 84%|████████▍ | 84/100 [07:32<01:29,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 85%|████████▌ | 85/100 [07:37<01:22,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 86%|████████▌ | 86/100 [07:40<01:07,  4.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 87%|████████▋ | 87/100 [07:45<01:02,  4.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 88%|████████▊ | 88/100 [07:53<01:06,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 89%|████████▉ | 89/100 [08:00<01:05,  5.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 90%|█████████ | 90/100 [08:04<00:54,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 91%|█████████ | 91/100 [08:10<00:50,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 92%|█████████▏| 92/100 [08:15<00:43,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 93%|█████████▎| 93/100 [08:22<00:40,  5.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 94%|█████████▍| 94/100 [08:26<00:32,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 95%|█████████▌| 95/100 [08:34<00:30,  6.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 96%|█████████▌| 96/100 [08:42<00:26,  6.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 97%|█████████▋| 97/100 [08:47<00:18,  6.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 98%|█████████▊| 98/100 [08:51<00:11,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 99%|█████████▉| 99/100 [08:58<00:06,  6.17s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "100%|██████████| 100/100 [09:06<00:00,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on MMLU: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation\n",
    "accuracy = evaluate(dataset, model, processor, max=100)\n",
    "print(f\"Accuracy on MMLU: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
